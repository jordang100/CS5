Algorithms have potential to make human interactions fairer. As David Oppenheimer said, “Even if [algorithms] are not designed with the intent of discriminating against those groups, if they reproduce social preferences even in a completely rational way, they also reproduce those forms of discrimination. Hence, by simply not designing an algorithm to “reproduce social preferences,” algorithms would not have to take in bias. For example, an employer’s algorithm could just take in college info (excluding single-gender schools), awards, etc… to judge a person and exclude bias-inducing factors such as gender, income, etc.... This type of selection is similar to a story my high school conductor once told me; when auditioning for an orchestra, interviewers are separated from the auditioner and can only hear the auditioners’ music since there bias against women being in orchestras. Hence why some women also don’t wear heels when auditioning so the interviewers can’t distinguish that they are female. Therefore, by taking away potentially biased inputs, algorithms have potential to be impartial. 